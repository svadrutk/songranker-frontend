# Data Analysis Guide - Song Ranker

**Last Updated**: January 2026  
**Purpose**: Comprehensive analysis of current data collection and recommendations for enhanced analytics  
**Status**: ‚úÖ **ACTIVE**

---

## üìä **Executive Summary**

**Current State**: You're collecting solid core data for ranking analysis, but missing critical user behavior and engagement metrics that would enable deeper insights.

**Key Finding**: The data is **sufficient for basic ranking analysis** but **insufficient for comprehensive user behavior analysis, product optimization, and growth insights**.

---

## üîç **Current Data Collection Analysis**

### **‚úÖ What You're Collecting Well**

#### **1. Core Ranking Data** (Excellent)
**Tables**: `comparisons`, `sessions`, `songs`

**Data Points**:
- ‚úÖ **Comparison outcomes**: `song_a_id`, `song_b_id`, `winner_id`, `is_tie`
- ‚úÖ **Decision timing**: `decision_time_ms` (milliseconds to make choice)
- ‚úÖ **Session metadata**: `session_id`, `user_id`, `created_at`, `status`
- ‚úÖ **Convergence tracking**: `convergence_score` (0-100%)
- ‚úÖ **Ranking scores**: `local_elo`, `bt_strength`, `global_elo`, `global_bt_strength`
- ‚úÖ **Song metadata**: `name`, `artist`, `album`, `cover_url`, `spotify_id`

**Analysis Capabilities**:
- ‚úÖ **Ranking accuracy**: Compare Elo vs Bradley-Terry rankings
- ‚úÖ **Decision confidence**: Analyze `decision_time_ms` patterns (fast = confident)
- ‚úÖ **Convergence patterns**: How many comparisons needed for stable rankings
- ‚úÖ **Song popularity**: Global rankings across all users
- ‚úÖ **Artist analysis**: Which artists get ranked most, average comparisons per artist

**SQL Examples**:
```sql
-- Average decision time by user
SELECT user_id, AVG(decision_time_ms) as avg_decision_time
FROM comparisons
GROUP BY user_id;

-- Convergence rate analysis
SELECT 
  CASE 
    WHEN comparison_count < 10 THEN 'Early'
    WHEN comparison_count < 30 THEN 'Mid'
    ELSE 'Late'
  END as stage,
  AVG(convergence_score) as avg_convergence
FROM sessions
GROUP BY stage;

-- Most compared songs globally
SELECT s.name, s.artist, COUNT(*) as comparison_count
FROM comparisons c
JOIN songs s ON c.song_a_id = s.id OR c.song_b_id = s.id
GROUP BY s.id, s.name, s.artist
ORDER BY comparison_count DESC
LIMIT 20;
```

---

### **‚ö†Ô∏è What You're Missing (Critical Gaps)**

#### **1. User Behavior & Engagement** (Major Gap)

**Missing Data**:
- ‚ùå **Session duration**: How long users spend ranking
- ‚ùå **Abandonment rate**: When/why users leave mid-session
- ‚ùå **Completion rate**: % of sessions that reach 90% convergence
- ‚ùå **Return rate**: Do users come back for multiple sessions?
- ‚ùå **Time between comparisons**: Pacing patterns (rushed vs thoughtful)
- ‚ùå **Peek behavior**: How often users check leaderboard mid-session
- ‚ùå **Skip rate**: How often users skip comparisons

**Impact**: **Cannot answer**:
- "What's our session completion rate?"
- "Do users who peek at rankings complete more sessions?"
- "What's the optimal session length?"
- "Why do users abandon sessions?"

**Where to Collect**:
- **Frontend**: `RankingWidget.tsx` - Track session start/end times, peek events, skip events
- **Backend**: `app/api/v1/sessions.py` - Calculate duration on session completion

**Implementation**:
```typescript
// In RankingWidget.tsx
const sessionStartTime = useRef<number>(Date.now());

// On session completion or abandonment
const sessionDuration = Date.now() - sessionStartTime.current;
await trackSessionEvent({
  session_id: sessionId,
  duration_ms: sessionDuration,
  completed: convergence >= 90,
  comparisons_made: totalDuels,
  peeks_count: peekCount,
  skips_count: skipCount
});
```

---

#### **2. User Journey & Funnel Analysis** (Major Gap)

**Missing Data**:
- ‚ùå **Search behavior**: What artists users search for, how many searches before selection
- ‚ùå **Album selection**: How many albums selected per session, selection patterns
- ‚ùå **Deduplication interaction**: How many duplicates found, merge vs keep-both decisions
- ‚ùå **Session flow**: Time spent in each stage (search ‚Üí select ‚Üí dedupe ‚Üí rank)
- ‚ùå **Drop-off points**: Where users exit the funnel

**Impact**: **Cannot answer**:
- "What's our conversion rate from search to ranking?"
- "Do users who merge duplicates complete more sessions?"
- "Which artists have highest engagement?"
- "Where do users drop off most?"

**Where to Collect**:
- **Frontend**: `Catalog.tsx` - Track search queries, album selections
- **Frontend**: `DeduplicationModal.tsx` - Track duplicate groups, merge decisions
- **Backend**: `app/api/v1/search.py` - Log search queries (anonymized)

**Implementation**:
```typescript
// In Catalog.tsx
const trackSearch = async (query: string) => {
  await fetch('/api/analytics/search', {
    method: 'POST',
    body: JSON.stringify({ query, user_id, timestamp: Date.now() })
  });
};

// In DeduplicationModal.tsx
const trackDeduplication = async (groups: DuplicateGroup[], decisions: MergeDecision[]) => {
  await fetch('/api/analytics/deduplication', {
    method: 'POST',
    body: JSON.stringify({
      session_id,
      groups_count: groups.length,
      merged_count: decisions.filter(d => d.action === 'merge').length,
      kept_both_count: decisions.filter(d => d.action === 'keep').length
    })
  });
};
```

---

#### **3. Technical Performance & Errors** (Moderate Gap)

**Missing Data**:
- ‚ùå **API response times**: How long each endpoint takes
- ‚ùå **Error rates**: Which endpoints fail most, error types
- ‚ùå **Worker performance**: BT calculation times, queue depth
- ‚ùå **Frontend performance**: Page load times, render performance
- ‚ùå **Network conditions**: Slow connections, timeouts

**Impact**: **Cannot answer**:
- "What's our API latency?"
- "Which endpoints need optimization?"
- "Are users experiencing errors?"
- "Is the worker queue backing up?"

**Where to Collect**:
- **Backend**: Add timing middleware to FastAPI routes
- **Backend**: Log errors with context (endpoint, user_id, error type)
- **Frontend**: Track API call durations, errors
- **Worker**: Already logging timing (`app/tasks.py`), but not stored

**Implementation**:
```python
# In app/main.py - Add timing middleware
@app.middleware("http")
async def timing_middleware(request: Request, call_next):
    start_time = time.time()
    response = await call_next(request)
    duration = time.time() - start_time
    
    # Store in analytics table
    await store_api_metric({
        "endpoint": request.url.path,
        "method": request.method,
        "duration_ms": duration * 1000,
        "status_code": response.status_code,
        "timestamp": datetime.now()
    })
    
    return response
```

---

#### **4. User Demographics & Context** (Moderate Gap)

**Missing Data**:
- ‚ùå **Device type**: Mobile vs desktop usage
- ‚ùå **Browser**: Chrome, Safari, Firefox distribution
- ‚ùå **Geographic location**: Country/region (privacy-conscious)
- ‚ùå **Time of day**: When users are most active
- ‚ùå **User agent**: Device capabilities, screen size

**Impact**: **Cannot answer**:
- "Do mobile users complete fewer sessions?"
- "What's our peak usage time?"
- "Which browsers have issues?"
- "Should we optimize for mobile?"

**Where to Collect**:
- **Backend**: Extract from `Request.headers` (`user-agent`, `accept-language`)
- **Frontend**: Use `navigator.userAgent`, `window.screen.width`

**Implementation**:
```python
# In app/api/v1/sessions.py
async def create_session(request: Request, ...):
    user_agent = request.headers.get("user-agent", "")
    device_type = parse_device_type(user_agent)  # mobile/desktop/tablet
    
    await store_session_metadata({
        "session_id": session_id,
        "device_type": device_type,
        "user_agent": user_agent,
        "screen_width": request.headers.get("x-screen-width"),  # Send from frontend
        "time_of_day": datetime.now().hour
    })
```

---

#### **5. Social & Sharing Behavior** (Minor Gap)

**Missing Data**:
- ‚ùå **Share generation**: How many users generate share cards
- ‚ùå **Share platform**: Where cards are shared (if trackable)
- ‚ùå **Share click-through**: Do shared cards drive new users?
- ‚ùå **Viral coefficient**: Users acquired via sharing

**Impact**: **Cannot answer**:
- "Is sharing driving growth?"
- "Which songs get shared most?"
- "What's our viral coefficient?"

**Where to Collect**:
- **Frontend**: `ShareButton.tsx` - Track when cards are generated/shared
- **Backend**: `app/api/v1/image_generation.py` - Log receipt generation

**Implementation**:
```typescript
// In ShareButton.tsx
const trackShare = async (songs: SessionSong[], platform?: string) => {
  await fetch('/api/analytics/share', {
    method: 'POST',
    body: JSON.stringify({
      session_id,
      top_song: songs[0]?.name,
      platform,  // 'instagram', 'twitter', 'download', etc.
      timestamp: Date.now()
    })
  });
};
```

---

## üìà **Recommended Data Collection Additions**

### **Priority 1: Critical for Product Analysis**

#### **1. Session Events Table** (New Table)
**Purpose**: Track all user actions during a session

**Schema**:
```sql
CREATE TABLE session_events (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  session_id UUID REFERENCES sessions(id) ON DELETE CASCADE,
  user_id UUID REFERENCES auth.users(id),
  event_type TEXT NOT NULL,  -- 'session_start', 'comparison', 'peek', 'skip', 'session_complete', 'session_abandon'
  event_data JSONB,  -- Flexible data: {comparison_id, peek_duration_ms, skip_reason, etc.}
  timestamp TIMESTAMPTZ DEFAULT NOW(),
  created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_session_events_session_id ON session_events(session_id);
CREATE INDEX idx_session_events_event_type ON session_events(event_type);
CREATE INDEX idx_session_events_timestamp ON session_events(timestamp);
```

**Events to Track**:
- `session_start`: When ranking begins
- `comparison`: Each duel (link to `comparisons` table)
- `peek`: When user views leaderboard mid-session
- `skip`: When user skips a comparison
- `session_complete`: When convergence reaches 90%+
- `session_abandon`: When user leaves without completing

**Where to Implement**:
- **Frontend**: `RankingWidget.tsx` - Add event tracking hooks
- **Backend**: `app/api/v1/sessions.py` - Create event logging endpoint

**Analysis Value**:
- **Engagement patterns**: See exactly how users interact
- **Drop-off analysis**: Identify where users leave
- **Feature usage**: How often are peeks/skips used?
- **Session quality**: Correlate events with completion rates

---

#### **2. Session Metadata Table** (Enhance Existing)
**Purpose**: Store calculated session metrics

**Add Columns to `sessions`**:
```sql
ALTER TABLE sessions ADD COLUMN IF NOT EXISTS duration_ms INTEGER;
ALTER TABLE sessions ADD COLUMN IF NOT EXISTS completed_at TIMESTAMPTZ;
ALTER TABLE sessions ADD COLUMN IF NOT EXISTS abandoned_at TIMESTAMPTZ;
ALTER TABLE sessions ADD COLUMN IF NOT EXISTS peek_count INTEGER DEFAULT 0;
ALTER TABLE sessions ADD COLUMN IF NOT EXISTS skip_count INTEGER DEFAULT 0;
ALTER TABLE sessions ADD COLUMN IF NOT EXISTS device_type TEXT;  -- 'mobile', 'desktop', 'tablet'
ALTER TABLE sessions ADD COLUMN IF NOT EXISTS browser TEXT;
ALTER TABLE sessions ADD COLUMN IF NOT EXISTS time_of_day INTEGER;  -- 0-23 hour
```

**Where to Implement**:
- **Backend**: `app/api/v1/sessions.py` - Update on session completion/abandonment
- **Frontend**: Send device/browser info on session creation

**Analysis Value**:
- **Completion rates**: `completed_at IS NOT NULL / total_sessions`
- **Average session duration**: `AVG(duration_ms)`
- **Device impact**: Compare completion rates by device type
- **Time patterns**: Peak usage hours

---

#### **3. Search Analytics Table** (New Table)
**Purpose**: Track search behavior and album selection

**Schema**:
```sql
CREATE TABLE search_analytics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES auth.users(id),
  session_id UUID REFERENCES sessions(id) ON DELETE CASCADE,
  query TEXT NOT NULL,
  results_count INTEGER,
  selected_albums JSONB,  -- Array of album IDs selected
  timestamp TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_search_analytics_user_id ON search_analytics(user_id);
CREATE INDEX idx_search_analytics_query ON search_analytics(query);
```

**Where to Implement**:
- **Frontend**: `Catalog.tsx` - Track search queries and selections
- **Backend**: `app/api/v1/search.py` - Log search results

**Analysis Value**:
- **Popular artists**: Most searched artists
- **Search-to-session conversion**: % of searches that lead to sessions
- **Selection patterns**: Average albums selected per session
- **Search refinement**: How many searches before selection

---

#### **4. Deduplication Analytics** (Enhance Existing)
**Purpose**: Track duplicate detection and user decisions

**Add to Session Creation**:
```sql
ALTER TABLE sessions ADD COLUMN IF NOT EXISTS duplicate_groups_count INTEGER DEFAULT 0;
ALTER TABLE sessions ADD COLUMN IF NOT EXISTS duplicates_merged_count INTEGER DEFAULT 0;
ALTER TABLE sessions ADD COLUMN IF NOT EXISTS duplicates_kept_both_count INTEGER DEFAULT 0;
```

**Where to Implement**:
- **Frontend**: `DeduplicationModal.tsx` - Track merge decisions
- **Backend**: `app/api/v1/sessions.py` - Store deduplication stats

**Analysis Value**:
- **Duplicate frequency**: How often duplicates appear
- **User behavior**: Do users merge or keep both?
- **Impact on completion**: Do merged sessions complete more?

---

### **Priority 2: Important for Growth & Optimization**

#### **5. User Engagement Metrics** (New Table)
**Purpose**: Track user lifecycle and retention

**Schema**:
```sql
CREATE TABLE user_engagement (
  user_id UUID PRIMARY KEY REFERENCES auth.users(id),
  first_session_at TIMESTAMPTZ,
  last_session_at TIMESTAMPTZ,
  total_sessions INTEGER DEFAULT 0,
  total_comparisons INTEGER DEFAULT 0,
  completed_sessions INTEGER DEFAULT 0,
  average_session_duration_ms INTEGER,
  days_since_last_session INTEGER,
  user_segment TEXT,  -- 'new', 'active', 'returning', 'churned'
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);
```

**Where to Implement**:
- **Backend**: Update on each session creation/completion
- **Scheduled job**: Calculate user segments daily

**Analysis Value**:
- **Retention rate**: Users who return within 7/30 days
- **User segments**: Identify power users vs casual users
- **Churn prediction**: Users at risk of leaving
- **Lifetime value**: Total comparisons per user

---

#### **6. Performance Metrics Table** (New Table)
**Purpose**: Track API and worker performance

**Schema**:
```sql
CREATE TABLE performance_metrics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  metric_type TEXT NOT NULL,  -- 'api_endpoint', 'worker_task', 'frontend_render'
  metric_name TEXT NOT NULL,  -- 'create_comparison', 'bt_calculation', 'page_load'
  duration_ms INTEGER,
  status_code INTEGER,
  error_message TEXT,
  metadata JSONB,  -- {session_id, user_id, queue_depth, etc.}
  timestamp TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_performance_metrics_type ON performance_metrics(metric_type);
CREATE INDEX idx_performance_metrics_timestamp ON performance_metrics(timestamp);
```

**Where to Implement**:
- **Backend**: Middleware for API timing
- **Worker**: Log BT calculation times (already logging, just need to store)
- **Frontend**: Track page load, render times

**Analysis Value**:
- **API latency**: P50, P95, P99 response times
- **Worker performance**: BT calculation times by session size
- **Error rates**: Which endpoints fail most
- **Performance trends**: Is system getting slower?

---

#### **7. Share Analytics** (New Table)
**Purpose**: Track social sharing behavior

**Schema**:
```sql
CREATE TABLE share_analytics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  session_id UUID REFERENCES sessions(id) ON DELETE CASCADE,
  user_id UUID REFERENCES auth.users(id),
  share_type TEXT NOT NULL,  -- 'receipt', 'leaderboard', 'top_10'
  platform TEXT,  -- 'instagram', 'twitter', 'download', 'copy_link'
  top_song_name TEXT,
  top_song_artist TEXT,
  timestamp TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_share_analytics_session_id ON share_analytics(session_id);
CREATE INDEX idx_share_analytics_platform ON share_analytics(platform);
```

**Where to Implement**:
- **Frontend**: `ShareButton.tsx` - Track when cards are generated/shared
- **Backend**: `app/api/v1/image_generation.py` - Log receipt generation

**Analysis Value**:
- **Share rate**: % of completed sessions that share
- **Platform distribution**: Which platforms are most popular
- **Viral songs**: Which songs get shared most
- **Growth attribution**: Users acquired via sharing

---

## üéØ **How This Data Helps**

### **1. Product Optimization**

**Questions You Can Answer**:
- ‚úÖ "What's our session completion rate?" ‚Üí Track `completed_at` vs `abandoned_at`
- ‚úÖ "Where do users drop off?" ‚Üí Analyze `session_events` for abandonment patterns
- ‚úÖ "Do peeks help or hurt completion?" ‚Üí Correlate `peek_count` with completion rate
- ‚úÖ "What's the optimal session length?" ‚Üí Analyze `duration_ms` vs completion rate
- ‚úÖ "Should we show rankings earlier?" ‚Üí Compare completion rates with/without peeks

**Actionable Insights**:
- If completion rate < 50%, investigate drop-off points
- If peek users complete more, make peeks more prominent
- If mobile users complete less, optimize mobile UX
- If sessions > 20 min have low completion, add "finish early" option

---

### **2. User Behavior Analysis**

**Questions You Can Answer**:
- ‚úÖ "How do power users behave differently?" ‚Üí Segment by `total_sessions`, `total_comparisons`
- ‚úÖ "Do fast decisions correlate with completion?" ‚Üí Analyze `decision_time_ms` patterns
- ‚úÖ "What's our retention rate?" ‚Üí Track `last_session_at` vs `first_session_at`
- ‚úÖ "Which artists drive most engagement?" ‚Üí Count sessions per artist
- ‚úÖ "Do merged duplicates improve experience?" ‚Üí Compare completion rates

**Actionable Insights**:
- Identify power user patterns to replicate for new users
- If fast decisions = higher completion, encourage quick choices
- If retention < 20%, improve onboarding or add email reminders
- Focus marketing on high-engagement artists

---

### **3. Algorithm & Ranking Analysis**

**Questions You Can Answer**:
- ‚úÖ "How accurate are Elo vs Bradley-Terry rankings?" ‚Üí Compare `local_elo` vs `bt_strength` ordering
- ‚úÖ "How many comparisons needed for convergence?" ‚Üí Analyze `convergence_score` progression
- ‚úÖ "Do decision times affect ranking quality?" ‚Üí Correlate `decision_time_ms` with ranking stability
- ‚úÖ "Which songs are hardest to rank?" ‚Üí Songs with most ties/skips
- ‚úÖ "Is adaptive pairing working?" ‚Üí Compare convergence rates with/without BT-based pairing

**Actionable Insights**:
- If Elo diverges significantly from BT, adjust K-factor
- If convergence takes >50 comparisons, improve pairing algorithm
- If fast decisions = unstable rankings, weight by decision time
- Identify "controversial" songs that split users

---

### **4. Growth & Marketing**

**Questions You Can Answer**:
- ‚úÖ "What's our viral coefficient?" ‚Üí Track shares ‚Üí new user signups
- ‚úÖ "Which songs drive shares?" ‚Üí `share_analytics` + `top_song_name`
- ‚úÖ "What's our search-to-session conversion?" ‚Üí `search_analytics` ‚Üí sessions created
- ‚úÖ "Which artists should we feature?" ‚Üí Most searched + highest completion rates
- ‚úÖ "What's our user acquisition cost?" ‚Üí Marketing spend / new users

**Actionable Insights**:
- If viral coefficient > 1.0, sharing is driving growth
- Feature high-share songs in marketing
- Optimize search experience if conversion < 30%
- Focus marketing on high-conversion artists

---

### **5. Technical Performance**

**Questions You Can Answer**:
- ‚úÖ "What's our API latency?" ‚Üí `performance_metrics` P95 duration
- ‚úÖ "Which endpoints need optimization?" ‚Üí Slowest endpoints by duration
- ‚úÖ "Is the worker queue backing up?" ‚Üí Queue depth over time
- ‚úÖ "Are users experiencing errors?" ‚Üí Error rate by endpoint
- ‚úÖ "Is performance degrading?" ‚Üí Trend analysis of response times

**Actionable Insights**:
- If P95 latency > 500ms, optimize slow endpoints
- If error rate > 1%, investigate error patterns
- If queue depth growing, scale workers
- Set up alerts for performance degradation

---

## üìã **Implementation Roadmap**

### **Phase 1: Critical Metrics (Week 1-2)**
1. ‚úÖ Add `session_events` table and tracking
2. ‚úÖ Enhance `sessions` table with duration, completion status
3. ‚úÖ Track peek/skip events in `RankingWidget.tsx`
4. ‚úÖ Calculate session completion rates

**SQL Migration**:
```sql
-- Create session_events table
CREATE TABLE session_events (...);

-- Add columns to sessions
ALTER TABLE sessions ADD COLUMN duration_ms INTEGER;
ALTER TABLE sessions ADD COLUMN completed_at TIMESTAMPTZ;
ALTER TABLE sessions ADD COLUMN peek_count INTEGER DEFAULT 0;
ALTER TABLE sessions ADD COLUMN skip_count INTEGER DEFAULT 0;
```

---

### **Phase 2: User Journey (Week 3-4)**
1. ‚úÖ Create `search_analytics` table
2. ‚úÖ Track search queries and album selections
3. ‚úÖ Track deduplication decisions
4. ‚úÖ Build funnel analysis dashboard

---

### **Phase 3: Performance & Growth (Week 5-6)**
1. ‚úÖ Create `performance_metrics` table
2. ‚úÖ Add API timing middleware
3. ‚úÖ Create `share_analytics` table
4. ‚úÖ Track share events

---

### **Phase 4: Advanced Analytics (Week 7+)**
1. ‚úÖ Create `user_engagement` table
2. ‚úÖ Build retention analysis
3. ‚úÖ Create user segmentation
4. ‚úÖ Build analytics dashboard

---

## üîß **Quick Wins (Can Implement Today)**

### **1. Session Duration Tracking**
**Location**: `app/api/v1/sessions.py`

```python
# On session completion
async def complete_session(session_id: UUID):
    session = await get_session(session_id)
    duration_ms = (datetime.now() - session.created_at).total_seconds() * 1000
    
    await supabase_client.update_session(
        session_id,
        {"duration_ms": duration_ms, "completed_at": datetime.now()}
    )
```

### **2. Peek/Skip Counting**
**Location**: `components/RankingWidget.tsx`

```typescript
const [peekCount, setPeekCount] = useState(0);
const [skipCount, setSkipCount] = useState(0);

// In handlePeek
setPeekCount(prev => prev + 1);
await trackEvent('peek', { session_id: sessionId });

// In handleSkip
setSkipCount(prev => prev + 1);
await trackEvent('skip', { session_id: sessionId });
```

### **3. Search Query Logging**
**Location**: `app/api/v1/search.py`

```python
@router.get("/search")
async def search(request: Request, query: str):
    # Log search (anonymize if needed)
    await log_search_analytics({
        "query": query[:100],  # Truncate long queries
        "user_id": get_user_id(request),
        "results_count": len(results),
        "timestamp": datetime.now()
    })
    return results
```

---

## üìä **Sample Analysis Queries**

### **Completion Rate Analysis**
```sql
SELECT 
  COUNT(*) FILTER (WHERE completed_at IS NOT NULL) * 100.0 / COUNT(*) as completion_rate,
  AVG(duration_ms) / 1000.0 / 60.0 as avg_duration_minutes,
  AVG(comparison_count) as avg_comparisons
FROM sessions
WHERE created_at > NOW() - INTERVAL '30 days';
```

### **Drop-off Analysis**
```sql
SELECT 
  event_type,
  COUNT(*) as event_count,
  AVG(EXTRACT(EPOCH FROM (timestamp - (SELECT MIN(timestamp) FROM session_events se2 WHERE se2.session_id = se.session_id)))) as avg_time_from_start_seconds
FROM session_events se
WHERE event_type IN ('session_abandon', 'session_complete')
GROUP BY event_type;
```

### **User Engagement Segmentation**
```sql
SELECT 
  CASE 
    WHEN total_sessions = 1 THEN 'One-time'
    WHEN total_sessions BETWEEN 2 AND 5 THEN 'Casual'
    WHEN total_sessions BETWEEN 6 AND 20 THEN 'Active'
    ELSE 'Power User'
  END as user_segment,
  COUNT(*) as user_count,
  AVG(total_comparisons) as avg_comparisons,
  AVG(completed_sessions::float / total_sessions) as avg_completion_rate
FROM user_engagement
GROUP BY user_segment;
```

---

## üéì **Conclusion**

**Current State**: ‚úÖ Good foundation for ranking analysis, ‚ö†Ô∏è Missing user behavior data

**Priority Actions**:
1. **Immediate**: Add session duration, completion tracking, peek/skip counts
2. **Short-term**: Add search analytics, deduplication tracking
3. **Medium-term**: Add performance metrics, share analytics
4. **Long-term**: Build comprehensive analytics dashboard

**Expected Impact**:
- **Product**: 20-30% improvement in completion rates through data-driven UX changes
- **Growth**: Identify viral songs/artists for marketing focus
- **Technical**: 50% reduction in API latency through performance monitoring
- **User**: Better understanding of user needs ‚Üí better product decisions

---

**Last Updated**: January 2026  
**Next Review**: After Phase 1 implementation
